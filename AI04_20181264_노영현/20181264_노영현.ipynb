{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "ZJFbNjqKjjht"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ggMHzU2KtFu3",
    "outputId": "642bd42c-15c6-4446-b8a0-fd8081a53063"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device_check: cpu\n"
     ]
    }
   ],
   "source": [
    "device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print('device_check:',device) # GPU 사용이 가능하면 cuda 출력 / 불가능하면 cpu 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dVgFeSPP72P2"
   },
   "source": [
    "# Section I. PyTorch 이용하여 MLP 만들기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6w0CR4zGpm_B"
   },
   "source": [
    "# One-Layer Perceptron 예제\n",
    "## PyTorch에서는 torch.nn.Linear를 이용하여 간단하게 perceptron을 구현할 수 있다.\n",
    "## torch.nn.Linear의 paramters\n",
    "* in_features: input data (2차원 행렬)에서 column의 개수\n",
    "* out_features: output data (2차원 행렬)에서 column의 개수\n",
    "\n",
    "## torch.nn.Linear의 input\n",
    "* input은 [batch_size, row, column] 사이즈를 가진 행렬 형태여야 한다. (row X column 행렬)\n",
    "* batch_size란 row X column 행렬이 독립적으로 몇 개 존재하는지 정도로 이해하도록 한다.\n",
    "* batch_size에 대해 더 궁금한 점은 검색해서 찾아보기\n",
    "\n",
    "## GPU 사용\n",
    "#### model = model.to(device) 로 선언한 후\n",
    "#### model의 input data 역시 input_data = input_data.to(device)로 선언해주어야 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8t2dPf0epSLV",
    "outputId": "38f47bd8-793c-4302-b978-6279a0fbdbd8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output 사이즈: torch.Size([5, 12, 8])\n"
     ]
    }
   ],
   "source": [
    "# nn.Linear 예제\n",
    "\n",
    "one_layer = nn.Linear(3,8).to(device)\n",
    "input_data = torch.randn(5,12,3).to(device) # 12 X 3 행렬이 독립적으로 5개 있음을 의미함\n",
    "out = one_layer(input_data)\n",
    "print(f'output 사이즈: {out.size()}') # [5, 12, 8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_Di8VgkoznrO"
   },
   "source": [
    "# Two-Layer Perceptron 예제\n",
    "## nn.Sequential은 두 개의 레이어가 순차적으로 실행되게 하는 함수이다.\n",
    "### 아래 예제에서 input_data는 처음 perceptron nn.Linear(3,8)을 통과한 후 [5,12,8]의 사이즈를 가지게 된다.\n",
    "### 바로 다음 두번째 perceptron nn.Linear(8,16)을 통과한 후에는 [5,12,16]의 사이즈를 가지게 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lVKqcK6oznKA",
    "outputId": "167d4319-f67c-426a-f5b8-360afc1a4a92"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output 사이즈: torch.Size([5, 12, 16])\n"
     ]
    }
   ],
   "source": [
    "# nn.Sequential 예제\n",
    "\n",
    "two_layer = nn.Sequential(nn.Linear(3,8),\n",
    "                          nn.Linear(8,16)).to(device)\n",
    "input_data = torch.randn(5,12,3).to(device) # 12 X 3 행렬이 독립적으로 5개 있음을 의미함\n",
    "out = two_layer(input_data)\n",
    "print(f'output 사이즈: {out.size()}') # [5, 12, 16]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T8GRA24a3HBN"
   },
   "source": [
    "# Activation Function\n",
    "### activation function은 neural network의 layer를 통과한 후 output data 변형을 주는 함수이다.\n",
    "### 일반적으로 neural network의 layer는 linear이기 때문에 activation function로는 non-linear 함수를 많이 사용한다.\n",
    "### 이를 통해 neural network가 단일 linear function으로 귀결되는 것을 방지하고, 결과적으로 성능향상을 이끌 수 있다.\n",
    "\n",
    "### 대표적인 activation function (nn 모듈을 이용하여 사용가능)\n",
    "* Sigmoid (시그모이드)\n",
    "* ReLU (렐루)\n",
    "* tanh (하이퍼볼릭 탄제트)\n",
    "#### 각 함수의 수식은 각자 검색하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8m3OmtGY3HRz",
    "outputId": "ee28dd3d-4891-44db-869e-83d825b24dc8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "인풋데이터 확인\n",
      "tensor([[[ 0.3607, -0.2859, -0.3938],\n",
      "         [ 0.2429, -1.3833, -2.3134],\n",
      "         [-0.3172, -0.8660,  1.7482],\n",
      "         [-0.2759, -0.9755,  0.4790],\n",
      "         [-2.3652, -0.8047,  0.6587]]])\n",
      "시그모이드 아웃풋\n",
      "tensor([[[0.5892, 0.4290, 0.4028],\n",
      "         [0.5604, 0.2005, 0.0900],\n",
      "         [0.4214, 0.2961, 0.8517],\n",
      "         [0.4315, 0.2738, 0.6175],\n",
      "         [0.0859, 0.3090, 0.6590]]])\n",
      "렐루 아웃풋\n",
      "tensor([[[0.3607, 0.0000, 0.0000],\n",
      "         [0.2429, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 1.7482],\n",
      "         [0.0000, 0.0000, 0.4790],\n",
      "         [0.0000, 0.0000, 0.6587]]])\n",
      "하이퍼볼릭 탄젠트 아웃풋\n",
      "tensor([[[ 0.3458, -0.2784, -0.3746],\n",
      "         [ 0.2383, -0.8817, -0.9806],\n",
      "         [-0.3070, -0.6994,  0.9412],\n",
      "         [-0.2691, -0.7511,  0.4454],\n",
      "         [-0.9825, -0.6666,  0.5775]]])\n"
     ]
    }
   ],
   "source": [
    "# activation function 예제\n",
    "sigmoid = nn.Sigmoid()\n",
    "relu = nn.ReLU()\n",
    "tanh = nn.Tanh()\n",
    "\n",
    "torch.random.manual_seed(100) # 랜덤시드 고정\n",
    "input_data = torch.randn(1,5,3)\n",
    "\n",
    "print('인풋데이터 확인')\n",
    "print(input_data)\n",
    "\n",
    "sigmoid_output = sigmoid(input_data)\n",
    "relu_output = relu(input_data)\n",
    "tanh_output = tanh(input_data)\n",
    "\n",
    "print('시그모이드 아웃풋')\n",
    "print(sigmoid_output)\n",
    "\n",
    "print('렐루 아웃풋')\n",
    "print(relu_output)\n",
    "\n",
    "print('하이퍼볼릭 탄젠트 아웃풋')\n",
    "print(tanh_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_hOb4jne8I5d",
    "outputId": "5c647260-1381-4379-fa42-486cd0aa1ebe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output 사이즈: torch.Size([5, 12, 16])\n"
     ]
    }
   ],
   "source": [
    "# nn.Linear + nn.Sequential + activation function 종합 예제\n",
    "my_model = nn.Sequential(nn.Linear(3,8),\n",
    "                         nn.Sigmoid(),\n",
    "                         nn.Linear(8,16),\n",
    "                         nn.ReLU()).to(device)\n",
    "input_data = torch.randn(5,12,3).to(device)\n",
    "out = my_model(input_data)\n",
    "print(f'output 사이즈: {out.size()}') # [5, 12, 16]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n8sI-sQC0mJC"
   },
   "source": [
    "# 문제1\n",
    "## nn.Linear와 nn.Sequential을 사용하여 Five-Layer Perceptron을 구현하시오. (1점)\n",
    "### 조건\n",
    "* input data 행렬의 row는 12, column은 3이다.\n",
    "* output 행렬의 column은 7이다.\n",
    "* 각 중간 layer의 out_features는 다음 순서를 따른다: [12,14,15,10,7]\n",
    "* activation function은 추가하지 않는다.\n",
    "* five_layer 모델은 GPU에서 실행되게 선언해야 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5N0rbCni0LWT",
    "outputId": "85bb113b-e8b5-4434-bd72-fa7f391b2331"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output 사이즈: torch.Size([5, 12, 7])\n"
     ]
    }
   ],
   "source": [
    "five_layer = None\n",
    "######################## TODO ########################\n",
    "five_layer = nn.Sequential(nn.Linear(3, 12), nn.Linear(12, 14), nn.Linear(14,15), nn.Linear(15, 10), nn.Linear(10, 7)).to(device)\n",
    "######################################################\n",
    "input_data = torch.randn(5,12,3).to(device)\n",
    "out = five_layer(input_data)\n",
    "print(f'output 사이즈: {out.size()}') # [5, 12, 7]이 출력되어야 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a4qRlNaqKIsM"
   },
   "source": [
    "# 문제2\n",
    "## nn.Linear, nn.Sequential, activation function을 사용하여 Ten-Layer Perceptron을 구현하시오. (1점)\n",
    "\n",
    "### 조건\n",
    "* activation은 Sigmoid, ReLU, tanh 중 하나를 사용한다.\n",
    "* input data 행렬의 row는 12, column은 3이다.\n",
    "* output 행렬의 column은 아래 조건을 참고하여 알맞게 나오도록 한다.\n",
    "* 각 중간 layer의 out_features는 초항이 5, 공차가 2인 등차수열을 따른다. (즉, [5,7,9,...])\n",
    "* ten_layer 모델은 GPU에서 실행되게 선언해야 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4RFDC0nqKIUn",
    "outputId": "6561d8ac-b4e3-497b-e74a-94f001899668"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output 사이즈: torch.Size([5, 12, 23])\n"
     ]
    }
   ],
   "source": [
    "ten_layer = None\n",
    "######################## TODO ########################\n",
    "ten_layer = nn.Sequential(nn.Linear(3, 5), nn.ReLU(), nn.Linear(5, 7), nn.ReLU(), nn.Linear(7, 9), nn.ReLU(), nn.Linear(9, 11), nn.ReLU(), nn.Linear(11, 13), nn.ReLU(), nn.Linear(13, 15), nn.ReLU(), nn.Linear(15, 17), nn.ReLU(), nn.Linear(17, 19), nn.ReLU(), nn.Linear(19, 21), nn.ReLU(), nn.Linear(21, 23), nn.ReLU()).to(device)\n",
    "######################################################\n",
    "input_data = torch.randn(5,12,3).to(device)\n",
    "out = ten_layer(input_data)\n",
    "print(f'output 사이즈: {out.size()}') # 위 조건에 알맞은 사이즈가 출력되어야 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jzIiF9VudYEP"
   },
   "source": [
    "# nn.Module 클래스 사용\n",
    "### PyTorch의 장점은 nn.Moudule 클래스를 상속 받아서 사용자가 원하는 neural network를 구성할 수 있다는 점이다.\n",
    "\n",
    "### class 함수 설명\n",
    "* \\_\\_init\\_\\_: 클래스의 인스턴스를 생성할 때 가장 먼저 수행되는 부분. neural network에서 사용할 layer 또는 activation function 등을 정의한다.\n",
    "* forward: 실제로 neural network의 작동을 제어하는 함수. input data를 받은 후 neural network의 각 layer별 실행 순서를 정하고, 최종 output을 return한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9ynaMgPGaLfT",
    "outputId": "408bd2a8-d780-41fb-f070-66b648313285"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output 사이즈: torch.Size([5, 12, 20])\n"
     ]
    }
   ],
   "source": [
    "# nn.Module 클래스 예시\n",
    "\n",
    "class MyMLP(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(MyMLP, self).__init__()\n",
    "    layers = [nn.Linear(3,8),\n",
    "              nn.Sigmoid(),\n",
    "              nn.Linear(8,20),\n",
    "              nn.ReLU()]\n",
    "    self.mlp = nn.Sequential(*layers) # 이러한 방식으로도 정의할 수 있다.\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = self.mlp(x)\n",
    "    return x\n",
    "\n",
    "my_model = MyMLP().to(device)\n",
    "input_data = torch.randn(5,12,3).to(device)\n",
    "out = my_model(input_data)\n",
    "print(f'output 사이즈: {out.size()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rQZTbtZqe3ai"
   },
   "source": [
    "# 문제3\n",
    "## 아래 조건에 맞게 nn.Module을 상속받는 클래스를 정의하시오. (3점)\n",
    "\n",
    "### 조건\n",
    "* MLP (Multi-Layer Perceptron)의 layer는 nn.Linear만 사용한다.\n",
    "* \\_\\_init\\_\\_ 함수의 parameter 중 num_layers는 MLP의 layer의 개수를 의미한다.\n",
    "* \\_\\_init\\_\\_ 함수의 parameter 중 out_feat_list는 순서대로 MLP의 layer들의 out_features를 원소로 가지고 있다. out_feat_list의 길이는 num_layers와 항상 동일해야만 한다. (assert문 참고)\n",
    "* \\_\\_init\\_\\_ 함수의 parameter 중 act는 activation function을 의미한다. MLP의 모든 layer 뒤에는 항상 해당 activation function이 위치해야 한다. 문자열(string)으로 입력되며 'sigmoid', 'relu', 'tanh'만  입력되도록 한다. (assert문 참고)\n",
    "* input_data 행렬의 column은 1024로 가정한다. (Hint: 이는 MLP의 첫번째 nn.LInear layer의 input_features과 동일하다.)\n",
    "* 입력 및 모델 구조 출력 예시를 참고한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "r-0TP5iye3rR",
    "outputId": "86ccbdc9-3abb-4ef6-a635-25c58a1e75a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CustomMLP(\n",
      "  (mlp): Sequential(\n",
      "    (0): Linear(in_features=1024, out_features=6, bias=True)\n",
      "    (1): Sigmoid()\n",
      "    (2): Linear(in_features=6, out_features=8, bias=True)\n",
      "    (3): Sigmoid()\n",
      "    (4): Linear(in_features=8, out_features=3, bias=True)\n",
      "    (5): Sigmoid()\n",
      "    (6): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (7): Sigmoid()\n",
      "    (8): Linear(in_features=4, out_features=9, bias=True)\n",
      "    (9): Sigmoid()\n",
      "    (10): Linear(in_features=9, out_features=10, bias=True)\n",
      "    (11): Sigmoid()\n",
      "    (12): Linear(in_features=10, out_features=2, bias=True)\n",
      "    (13): Sigmoid()\n",
      "    (14): Linear(in_features=2, out_features=4, bias=True)\n",
      "    (15): Sigmoid()\n",
      "  )\n",
      ")\n",
      "CustomMLP(\n",
      "  (mlp): Sequential(\n",
      "    (0): Linear(in_features=1024, out_features=5, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=5, out_features=8, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=8, out_features=13, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=13, out_features=6, bias=True)\n",
      "    (7): ReLU()\n",
      "    (8): Linear(in_features=6, out_features=4, bias=True)\n",
      "    (9): ReLU()\n",
      "    (10): Linear(in_features=4, out_features=9, bias=True)\n",
      "    (11): ReLU()\n",
      "    (12): Linear(in_features=9, out_features=9, bias=True)\n",
      "    (13): ReLU()\n",
      "    (14): Linear(in_features=9, out_features=2, bias=True)\n",
      "    (15): ReLU()\n",
      "    (16): Linear(in_features=2, out_features=6, bias=True)\n",
      "    (17): ReLU()\n",
      "    (18): Linear(in_features=6, out_features=3, bias=True)\n",
      "    (19): ReLU()\n",
      "    (20): Linear(in_features=3, out_features=9, bias=True)\n",
      "    (21): ReLU()\n",
      "    (22): Linear(in_features=9, out_features=10, bias=True)\n",
      "    (23): ReLU()\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'\\n출력결과\\nCustomMLP(\\n  (mlp): Sequential(\\n    (0): Linear(in_features=1024, out_features=5, bias=True)\\n    (1): ReLU()\\n    (2): Linear(in_features=5, out_features=8, bias=True)\\n    (3): ReLU()\\n    (4): Linear(in_features=8, out_features=13, bias=True)\\n    (5): ReLU()\\n    (6): Linear(in_features=13, out_features=6, bias=True)\\n    (7): ReLU()\\n    (8): Linear(in_features=6, out_features=4, bias=True)\\n    (9): ReLU()\\n    (10): Linear(in_features=4, out_features=9, bias=True)\\n    (11): ReLU()\\n    (12): Linear(in_features=9, out_features=9, bias=True)\\n    (13): ReLU()\\n    (14): Linear(in_features=9, out_features=2, bias=True)\\n    (15): ReLU()\\n    (16): Linear(in_features=2, out_features=6, bias=True)\\n    (17): ReLU()\\n    (18): Linear(in_features=6, out_features=3, bias=True)\\n    (19): ReLU()\\n    (20): Linear(in_features=3, out_features=9, bias=True)\\n    (21): ReLU()\\n    (22): Linear(in_features=9, out_features=10, bias=True)\\n    (23): ReLU()\\n  )\\n)\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class CustomMLP(nn.Module):\n",
    "  def __init__(self, num_layers: int, out_feat_list: List[int], act: str):\n",
    "    assert len(out_feat_list)==num_layers, 'out_feat_list size should be equal to num_layers'\n",
    "    super(CustomMLP, self).__init__()\n",
    "    activation = self.select_act(act)\n",
    "    layers = list()\n",
    "    ######################## TODO ########################\n",
    "    s = 1024\n",
    "    for i in out_feat_list:\n",
    "      layers.append(nn.Linear(s,i))\n",
    "      s = i\n",
    "      layers.append(activation)\n",
    "    ######################################################\n",
    "    self.mlp = nn.Sequential(*layers)\n",
    "  \n",
    "  def forward(self, x):\n",
    "    x = self.mlp(x)\n",
    "    return x\n",
    "\n",
    "  def select_act(self, act: str):\n",
    "    assert act in ['sigmoid', 'relu', 'tanh'], 'activation should be in [sigmoid, relu, tanh]'\n",
    "    if act == 'sigmoid':\n",
    "      return nn.Sigmoid()\n",
    "    elif act == 'relu':\n",
    "      return nn.ReLU()\n",
    "    else:\n",
    "      return nn.Tanh()\n",
    "\n",
    "model = CustomMLP(num_layers=8, out_feat_list=[6,8,3,4,9,10,2,4], act='sigmoid')\n",
    "print(model)\n",
    "'''\n",
    "출력결과\n",
    "CustomMLP(\n",
    "  (mlp): Sequential(\n",
    "    (0): Linear(in_features=1024, out_features=6, bias=True)\n",
    "    (1): Sigmoid()\n",
    "    (2): Linear(in_features=6, out_features=8, bias=True)\n",
    "    (3): Sigmoid()\n",
    "    (4): Linear(in_features=8, out_features=3, bias=True)\n",
    "    (5): Sigmoid()\n",
    "    (6): Linear(in_features=3, out_features=4, bias=True)\n",
    "    (7): Sigmoid()\n",
    "    (8): Linear(in_features=4, out_features=9, bias=True)\n",
    "    (9): Sigmoid()\n",
    "    (10): Linear(in_features=9, out_features=10, bias=True)\n",
    "    (11): Sigmoid()\n",
    "    (12): Linear(in_features=10, out_features=2, bias=True)\n",
    "    (13): Sigmoid()\n",
    "    (14): Linear(in_features=2, out_features=4, bias=True)\n",
    "    (15): Sigmoid()\n",
    "  )\n",
    ")\n",
    "'''\n",
    "\n",
    "model = CustomMLP(num_layers=12, out_feat_list=[5,8,13,6,4,9,9,2,6,3,9,10], act='relu')\n",
    "print(model)\n",
    "'''\n",
    "출력결과\n",
    "CustomMLP(\n",
    "  (mlp): Sequential(\n",
    "    (0): Linear(in_features=1024, out_features=5, bias=True)\n",
    "    (1): ReLU()\n",
    "    (2): Linear(in_features=5, out_features=8, bias=True)\n",
    "    (3): ReLU()\n",
    "    (4): Linear(in_features=8, out_features=13, bias=True)\n",
    "    (5): ReLU()\n",
    "    (6): Linear(in_features=13, out_features=6, bias=True)\n",
    "    (7): ReLU()\n",
    "    (8): Linear(in_features=6, out_features=4, bias=True)\n",
    "    (9): ReLU()\n",
    "    (10): Linear(in_features=4, out_features=9, bias=True)\n",
    "    (11): ReLU()\n",
    "    (12): Linear(in_features=9, out_features=9, bias=True)\n",
    "    (13): ReLU()\n",
    "    (14): Linear(in_features=9, out_features=2, bias=True)\n",
    "    (15): ReLU()\n",
    "    (16): Linear(in_features=2, out_features=6, bias=True)\n",
    "    (17): ReLU()\n",
    "    (18): Linear(in_features=6, out_features=3, bias=True)\n",
    "    (19): ReLU()\n",
    "    (20): Linear(in_features=3, out_features=9, bias=True)\n",
    "    (21): ReLU()\n",
    "    (22): Linear(in_features=9, out_features=10, bias=True)\n",
    "    (23): ReLU()\n",
    "  )\n",
    ")\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Le8rbkmcP0du"
   },
   "source": [
    "===================================================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JNwQ0rAmP0Uc"
   },
   "source": [
    "===================================================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qEM9XM-c7yL5"
   },
   "source": [
    "# Section II. 이미지 분류 예측 모델 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cKYBqeAHOcPb"
   },
   "source": [
    "# CIFAR10 데이터\n",
    "### train: 50,000장\n",
    "### test: 10,000장\n",
    "### label: 10개 (airplane, automobile, bird, cat, deer, dog, frog, horse, ship, truck)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EPGIRI5kPMeE",
    "outputId": "adabe46f-fe74-4ea2-e47a-fd53eac3d177"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /gdrive\n"
     ]
    }
   ],
   "source": [
    "# 구글 드라이브 사용 희망 시 아래 코드 주석 해제하고 실행\n",
    "from google.colab import drive\n",
    "drive.mount('/gdrive',force_remount=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "dZg9cAfWPGWG"
   },
   "outputs": [],
   "source": [
    "from torchvision import datasets\n",
    "from torchvision.transforms import functional as TF\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ygQxBQkLnNCt"
   },
   "source": [
    "# 코랩 임시 저장소 또는 구글 드라이브에 데이터 저장\n",
    "## 둘 중 원하는 방법 선택하여 실행\n",
    "#### 참고: 데이터 사이즈 약 350MB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 120,
     "referenced_widgets": [
      "9915c39b445e4a09bfb975e7be35e6eb",
      "4ef34b871ea34a54812de56fcf364d16",
      "334801352ea5479ea4e5ac00d44c61ff",
      "62d9372f14614ab2a0be20247b692c5e",
      "5683bd08a1b94a19b9ba6d4c15f20287",
      "928e1eaaa73449429a7a39f15b53651c",
      "88b368b94c0149a2bd3e4203cb645e4b",
      "59775e26317a41b0a35851e2435af1cf",
      "7a30f702a8ee4ba8b1946b11aac3042f",
      "c4d6d6ae0a2449348c0470a0f367eb2d",
      "e91840887d85459bb07616fe4ba90013"
     ]
    },
    "id": "L3pJ-j4Slj5O",
    "outputId": "dc6e1174-82d7-4f76-d28a-19e606f54a07"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to /content/drive/MyDrive/data/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9915c39b445e4a09bfb975e7be35e6eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/170498071 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /content/drive/MyDrive/data/cifar-10-python.tar.gz to /content/drive/MyDrive/data\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# 임시 저장소에 저장 / 코랩 런타임 끊길 경우 초기화\n",
    "# train_data = datasets.CIFAR10(root = './data', train = True, download = True)\n",
    "# test_data = datasets.CIFAR10(root = './data', train = False, download = True)\n",
    "\n",
    "# 구글 드라이브에 저장 / 코랩 런타임 끊기더라도 초기화 되지 않음\n",
    "trainset = datasets.CIFAR10(root = '/content/drive/MyDrive/data', train = True, download = True)\n",
    "testset = datasets.CIFAR10(root = '/content/drive/MyDrive/data', train = False, download = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mIno48Ofnp6P"
   },
   "source": [
    "# 데이터 상세정보 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xi1mezKinpYU",
    "outputId": "90753b57-9d0b-4f50-bfd1-f286098a6496"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000 10000\n"
     ]
    }
   ],
   "source": [
    "# data 사이즈 확인\n",
    "print(len(trainset), len(testset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "id": "s_MqoHXymhNC",
    "outputId": "f0e310f4-e3b9-45be-8c7d-0aa0b31fe2a2"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image type: <class 'PIL.Image.Image'>\n",
      "label: 6\n"
     ]
    }
   ],
   "source": [
    "# Train data 이미지 및 레이블 확인\n",
    "image, label = trainset[0]\n",
    "plt.imshow(image)\n",
    "plt.show()\n",
    "\n",
    "print(f'image type: {type(image)}')\n",
    "print(f'label: {label}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m14SHtCgoZNK"
   },
   "source": [
    "# PyTorch에서 neural network에 대한 모든 입력은 PyTorch에서 정의한 Tensor라는 자료구조를 사용해야 함\n",
    "### 위 셀에서 image type은 <class 'PIL.Image.Image'>이므로 변형 필요\n",
    "### TF.to_tensor 함수 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V4c3GRYonn0J",
    "outputId": "82423287-d14f-4984-c72e-b345ded68dea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image type: <class 'torch.Tensor'>\n",
      "image size: torch.Size([3, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "# PIL.Image.Image -> torch.Tensor로 변경\n",
    "image = TF.to_tensor(image)\n",
    "print(f'image type: {type(image)}')\n",
    "print(f'image size: {image.size()}') # 3채널(R,G,B), 32(height,세로), 32(width,가로)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jz9bFyyU5K3y"
   },
   "source": [
    "# 이미지 데이터에 Multi-Layer Perceptron (MLP) 적용하기 위한 pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EmrgzybDQAB7"
   },
   "source": [
    "### (review) nn.Linear의 인풋 데이터는 2차원 행렬 형태를 가져야 한다.\n",
    "### 하지만 CIFAR10과 같은 이미지 데이터의 경우 height, width 외에 channel이라는 차원을 가지고 있다. (즉 3차원 데이터)\n",
    "### 따라서 이러한 형태를 2차원 형태로 변환해주는 flattening 과정이 필요하다. (flatten 메소드 사용)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aTe99wwnP_pC",
    "outputId": "6d02b952-fab8-4ba6-ec46-231f5597ce8a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image size 확인: torch.Size([3, 32, 32])\n",
      "flattened image size 확인: torch.Size([3, 1024])\n"
     ]
    }
   ],
   "source": [
    "# flatten, permute\n",
    "image, label = trainset[1214] # train data 1개 load\n",
    "image = TF.to_tensor(image)\n",
    "print(f'image size 확인: {image.size()}')\n",
    "image_flat = image.flatten(start_dim=1, end_dim=2)\n",
    "print(f'flattened image size 확인: {image_flat.size()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7u6Gm_2V4nku"
   },
   "source": [
    "## Dataset 클래스를 새롭게 정의하여 CIFAR10 데이터셋에서 이미지를 불러올 때마다 flatten과 permute를 자동으로 수행하게 한다. 아래와 같이 선언 (코드 수정할 필요 없음)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t7MyKuhO3GXD",
    "outputId": "cbc3d2d0-7b22-4839-eee8-79882d5d65f9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image size 확인: torch.Size([3, 1024])\n"
     ]
    }
   ],
   "source": [
    "class Cifar10Dataset(Dataset):\n",
    "  def __init__(self, dataset, train=True):\n",
    "    super(Cifar10Dataset, self).__init__()\n",
    "    self.dataset = dataset\n",
    "    self.train = train\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.dataset)\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "    image, label = self.dataset[index]\n",
    "    image = TF.to_tensor(image)\n",
    "    image = image.flatten(start_dim=1, end_dim=2)\n",
    "    # image = image.permute(1,0)\n",
    "    return image, label\n",
    "\n",
    "train_data = Cifar10Dataset(trainset, train=True)\n",
    "test_data = Cifar10Dataset(testset, train=False)\n",
    "\n",
    "image, label = train_data[1234]\n",
    "print(f'image size 확인: {image.size()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YAGM9L5S45Ou"
   },
   "source": [
    "## DataLoader\n",
    "\n",
    "### 위처럼 정의된 Dataset에서 데이터를 한 번에 batch_size만큼 불러올 수 있는 기능\n",
    "### 아래와 같이 선언 (코드 수정할 필요 없음)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ROhJ2RSTZIUN",
    "outputId": "33d299ea-14a3-4e3c-f88a-f93b69a96ee3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image size 확인: torch.Size([128, 3, 1024])\n",
      "label size 확인: torch.Size([128])\n"
     ]
    }
   ],
   "source": [
    "# DataLoader 사용\n",
    "train_loader = DataLoader(train_data, batch_size=128, shuffle=False, pin_memory=True)\n",
    "test_loader = DataLoader(test_data, batch_size=128, shuffle=False, pin_memory=True)\n",
    "\n",
    "image, label = next(iter(train_loader))\n",
    "print(f'image size 확인: {image.size()}') # [128, 3, 1024] == [batch_size, channel(RGB), height*width]\n",
    "print(f'label size 확인: {label.size()}') # [128] == [batch_size]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NfKFs8Rb7qCc"
   },
   "source": [
    "# 본격적인 모델 학습을 위한 model, optimizer, loss function 정의\n",
    "# 학습 후 테스트 진행\n",
    "* 예시 코드 test 정확도 37.15%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "Gc37nVwc22hk"
   },
   "outputs": [],
   "source": [
    "# model, optimizer, loss function 정의 예시\n",
    "torch.random.manual_seed(100)\n",
    "model = CustomMLP(num_layers=5, out_feat_list=[1024,256,64,16,10], act='relu').to(device) # 문제3에서 생성한 CustomMLP 사용\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001) # Adam optimizer. lr: learning rate\n",
    "criterion = nn.CrossEntropyLoss() # loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 647
    },
    "id": "FX3jQVIT91Ha",
    "outputId": "9cb50c95-1571-4b4b-c5a3-a12e3ca25602"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:07<00:00, 50.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 average loss: 2.154141\n",
      "1 average accuracy: 20.92%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:07<00:00, 52.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 average loss: 2.045065\n",
      "2 average accuracy: 27.49%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:08<00:00, 46.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 average loss: 1.987662\n",
      "3 average accuracy: 29.77%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:07<00:00, 52.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 average loss: 1.950839\n",
      "4 average accuracy: 31.26%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:07<00:00, 51.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 average loss: 1.920937\n",
      "5 average accuracy: 32.57%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 83/391 [00:01<00:06, 50.96it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-df71a7ebc0f9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mtotal_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mtotal_right\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m   \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1194\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1195\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1196\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1197\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    626\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 628\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    629\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    669\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 671\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    672\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    673\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     56\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     56\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-16-67df4ea3ae27>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     10\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;31m# image = image.permute(1,0)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mto_tensor\u001b[0;34m(pic)\u001b[0m\n\u001b[1;32m    169\u001b[0m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mByteTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdefault_float_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# model training 예시 코드\n",
    "from tqdm import tqdm\n",
    "for epoch in range(20):\n",
    "  total_loss = 0.0\n",
    "  total_right = 0\n",
    "  for i, (image, label) in enumerate(tqdm(train_loader)):\n",
    "    image = image.to(device)\n",
    "    label = label.to(device)\n",
    "\n",
    "    # 모델 label 분류 예측\n",
    "    output = model(image)\n",
    "    output = output.max(1)[0]\n",
    "    \n",
    "    # loss 계산\n",
    "    loss = criterion(output, label.long())\n",
    "    total_loss += loss\n",
    "\n",
    "    # 정답을 맞춘 개수 계산\n",
    "    right = (output.max(1)[1] == label).sum()\n",
    "    total_right += right\n",
    "\n",
    "    # Back-Propagation\n",
    "    optimizer.zero_grad() \n",
    "    loss.backward() \n",
    "    optimizer.step()\n",
    "\n",
    "    if i==len(train_loader)-1:\n",
    "      print(f'{epoch+1} average loss: {total_loss/len(train_loader):.6f}')\n",
    "      print(f'{epoch+1} average accuracy: {total_right/len(train_loader.dataset)*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2PqWODPLWVJW",
    "outputId": "19a210cf-3a6a-453c-bd8a-99e413e2b813"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:01<00:00, 61.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST average accuracy: 37.15%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# test 예시 코드\n",
    "total_right = 0\n",
    "for i, (image, label) in enumerate(tqdm(test_loader)):\n",
    "  image = image.to(device)\n",
    "  label = label.to(device)\n",
    "\n",
    "  # 모델 label 분류 예측\n",
    "  output = model(image)\n",
    "  output = output.max(1)[0]\n",
    "\n",
    "  # 정답을 맞춘 개수 계산\n",
    "  right = (output.max(1)[1] == label).sum()\n",
    "  total_right += right\n",
    "\n",
    "  if i==len(test_loader)-1:\n",
    "    print(f'TEST average accuracy: {total_right/len(test_loader.dataset)*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0J4PjZWyDQtv"
   },
   "source": [
    "# 문제4\n",
    "## 아래 조건에 맞게 코드를 작성하고 test 정확도 40% 이상 달성 (5점)\n",
    "\n",
    "### 조건\n",
    "* model은 반드시 문제3에서 생성한 CustomMLP를 사용하도록 한다.\n",
    "* num_layers는 10이 넘지 않아야 한다.\n",
    "* out_feat_list에는 1024를 넘는 수가 없어야 한다.\n",
    "* activation function은 Sigmoid, ReLU, tanh 외에 소개되지 않은 것을 사용해도 상관 없다. 소개되지 않은 activation function을 사용할 경우 select_act 함수를 적절히 수정하도록 한다.\n",
    "* 아래 코드에서 수정해도 되는 것: CustomMLP의 모든 파라미터(단 위 조건에 맞아야 함), SEED, LEARNING_RATE, optimizer\n",
    "* 아래 코드에서 수정하면 안 되는 것: criterion, TRAINING PHASE, TEST PHASE\n",
    "* 성능평가: 테스트 정확도 40% 이상이면 만점, 40% 미만은 1% 구간 별로 1점씩 감점\n",
    "(예: 39.5% -> 1점 감점 38.7% -> 2점 감점)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2rE9cdrwDQR6",
    "outputId": "087bd5f3-e130-4d5b-8530-7e84e0d6ffd2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:08<00:00, 47.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 average loss: 2.230797\n",
      "1 average accuracy: 16.60%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:08<00:00, 47.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 average loss: 2.119312\n",
      "2 average accuracy: 24.75%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:08<00:00, 47.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 average loss: 2.039688\n",
      "3 average accuracy: 28.25%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:08<00:00, 47.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 average loss: 1.944154\n",
      "4 average accuracy: 31.84%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:08<00:00, 48.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 average loss: 1.898908\n",
      "5 average accuracy: 33.76%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:08<00:00, 47.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 average loss: 1.863960\n",
      "6 average accuracy: 35.38%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:08<00:00, 47.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 average loss: 1.833372\n",
      "7 average accuracy: 36.52%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:08<00:00, 47.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 average loss: 1.803237\n",
      "8 average accuracy: 37.64%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:08<00:00, 47.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 average loss: 1.773308\n",
      "9 average accuracy: 38.78%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:08<00:00, 47.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 average loss: 1.747669\n",
      "10 average accuracy: 39.72%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:08<00:00, 48.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 average loss: 1.720701\n",
      "11 average accuracy: 40.87%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:08<00:00, 48.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 average loss: 1.694878\n",
      "12 average accuracy: 41.98%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:08<00:00, 47.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13 average loss: 1.668514\n",
      "13 average accuracy: 42.93%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:08<00:00, 47.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14 average loss: 1.644722\n",
      "14 average accuracy: 43.97%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:08<00:00, 47.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 average loss: 1.623222\n",
      "15 average accuracy: 44.78%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:08<00:00, 48.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 average loss: 1.600467\n",
      "16 average accuracy: 45.81%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:08<00:00, 47.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17 average loss: 1.574920\n",
      "17 average accuracy: 46.84%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:08<00:00, 47.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18 average loss: 1.552686\n",
      "18 average accuracy: 47.46%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:08<00:00, 47.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19 average loss: 1.536309\n",
      "19 average accuracy: 48.19%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:08<00:00, 47.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 average loss: 1.510138\n",
      "20 average accuracy: 49.14%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:01<00:00, 55.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "TEST average accuracy: 41.37%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "####################################### TODO #######################################\n",
    "SEED = 100 # can be changed\n",
    "LEARNING_RATE = 0.001 # can be changed\n",
    "torch.random.manual_seed(SEED)\n",
    "model = CustomMLP(num_layers=8, out_feat_list=[1024,512,256,128,64,32,16,10], act='relu').to(device) # can be changed (but meet conditions above)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE) # can be changed\n",
    "####################################################################################\n",
    "criterion = nn.CrossEntropyLoss() # NEVER CHANGE!!\n",
    "\n",
    "#################################### TRAINING PHASE // NEVER EDIT!! ####################################\n",
    "from tqdm import tqdm\n",
    "for epoch in range(20):\n",
    "  total_loss = 0.0\n",
    "  total_right = 0\n",
    "  for i, (image, label) in enumerate(tqdm(train_loader)):\n",
    "    image = image.to(device)\n",
    "    label = label.to(device)\n",
    "\n",
    "    # 모델 label 분류 예측\n",
    "    output = model(image)\n",
    "    output = output.max(1)[0]\n",
    "    \n",
    "    # loss 계산\n",
    "    loss = criterion(output, label.long())\n",
    "    total_loss += loss\n",
    "\n",
    "    # 정답을 맞춘 개수 계산\n",
    "    right = (output.max(1)[1] == label).sum()\n",
    "    total_right += right\n",
    "\n",
    "    # Back-Propagation\n",
    "    optimizer.zero_grad() \n",
    "    loss.backward() \n",
    "    optimizer.step()\n",
    "\n",
    "    if i==len(train_loader)-1:\n",
    "      print(f'{epoch+1} average loss: {total_loss/len(train_loader):.6f}')\n",
    "      print(f'{epoch+1} average accuracy: {total_right/len(train_loader.dataset)*100:.2f}%')\n",
    "#######################################################################################################\n",
    "\n",
    "###################################### TEST PHASE // NEVER EDIT!! #####################################\n",
    "total_right = 0\n",
    "for i, (image, label) in enumerate(tqdm(test_loader)):\n",
    "  image = image.to(device)\n",
    "  label = label.to(device)\n",
    "\n",
    "  # 모델 label 분류 예측\n",
    "  output = model(image)\n",
    "  output = output.max(1)[0]\n",
    "\n",
    "  # 정답을 맞춘 개수 계산\n",
    "  right = (output.max(1)[1] == label).sum()\n",
    "  total_right += right\n",
    "\n",
    "print()\n",
    "print()\n",
    "print(f'TEST average accuracy: {total_right/len(test_loader.dataset)*100:.2f}%')\n",
    "#######################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KldOik_rfV48"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "334801352ea5479ea4e5ac00d44c61ff": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_59775e26317a41b0a35851e2435af1cf",
      "max": 170498071,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_7a30f702a8ee4ba8b1946b11aac3042f",
      "value": 170498071
     }
    },
    "4ef34b871ea34a54812de56fcf364d16": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_928e1eaaa73449429a7a39f15b53651c",
      "placeholder": "​",
      "style": "IPY_MODEL_88b368b94c0149a2bd3e4203cb645e4b",
      "value": "100%"
     }
    },
    "5683bd08a1b94a19b9ba6d4c15f20287": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "59775e26317a41b0a35851e2435af1cf": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "62d9372f14614ab2a0be20247b692c5e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c4d6d6ae0a2449348c0470a0f367eb2d",
      "placeholder": "​",
      "style": "IPY_MODEL_e91840887d85459bb07616fe4ba90013",
      "value": " 170498071/170498071 [00:03&lt;00:00, 84508060.67it/s]"
     }
    },
    "7a30f702a8ee4ba8b1946b11aac3042f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "88b368b94c0149a2bd3e4203cb645e4b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "928e1eaaa73449429a7a39f15b53651c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9915c39b445e4a09bfb975e7be35e6eb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_4ef34b871ea34a54812de56fcf364d16",
       "IPY_MODEL_334801352ea5479ea4e5ac00d44c61ff",
       "IPY_MODEL_62d9372f14614ab2a0be20247b692c5e"
      ],
      "layout": "IPY_MODEL_5683bd08a1b94a19b9ba6d4c15f20287"
     }
    },
    "c4d6d6ae0a2449348c0470a0f367eb2d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e91840887d85459bb07616fe4ba90013": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
